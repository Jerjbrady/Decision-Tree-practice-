import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import GridSearchCV
from sklearn.tree import DecisionTreeClassifier

# This function displays the splits of the tree
from sklearn.tree import plot_tree

from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix
from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score

#import data
df_original = pd.read_csv("Invistico_Airline.csv")

#check first ten rows
print(df_original.head(10))

#determine data type for each column 
print(df_original.describe)

#check if target data is imbalanced
print(df_original["satisfaction"].value_counts())

#check for missing values 
missing_values = df_original.isnull().sum(axis = 1).value_count()

print(missing_values)

# check the number of rows and number of columns
num_rows, num_columns = df_original.shape

# Display the results
print(f"Number of rows: {num_rows}")
print(f"Number of columns: {num_columns}")

#drop rows with missing values
df_subset = df_original.dropna().reset_index(drop = True)

#double check there is no missing values
print(df_subset.isnull().sum(axis = 1).value_counts())

#encode the data; 4 columns are datatype object. convert into numeric 
df_subset['Class'] = df_subset['Class'].map({"Business": 3, "Eco Plus": 2, "Eco": 1}) 

#convert values in target column to numeric; satisfied = 1 dissatisfied = 0
df_subset["satisfaction"] = df_subset["satisfaction"].map({"satisfied": 1, "dissatisfied": 0})

# the last two columns will be converted into numerics using get_dummies
df_subset = pd.get_dummies(df_subset, drop_first = True)

#split the data for training and testing
# define target variable 
y = df_subset["satisfaction"]

#define predictor variable

x = df_subset.copy()
x = x.drop("satisfaction", axis = 1)

# split data into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = .25, stratify = y, random_state = 42)

# make decision tree and fit model on training set
decision_tree = DecisionTreeClassifier(random_state=0)
decision_tree.fit(X_train, y_train)
#assign predictions to variable dt_pred
dt_pred = decision_tree.predict(X_test)

# Generate performance metrics
print("Accuracy:", "%.3f" % accuracy_score(y_test, dt_pred))
print("Precision:", "%.3f" % precision_score(y_test, dt_pred))
print("Recall:", "%.3f" % recall_score(y_test, dt_pred))
print("F1 Score:", "%.3f" % f1_score(y_test, dt_pred))

#create a confusion matrix
def conf_matrix_plot(model, x_data, y_data):
    '''
    Accepts as argument model object, X data (test or validate), and y data (test or validate). 
    Returns a plot of confusion matrix for predictions on y data.
    ''' 
  
    model_pred = model.predict(x_data)
    cm = confusion_matrix(y_data, model_pred, labels=model.classes_)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                             display_labels=model.classes_)
  
    disp.plot(values_format='')  # `values_format=''` suppresses scientific notation
    plt.show()

print(conf_matrix_plot(decision_tree, X_test, y_test))

# Plot the tree
plt.figure(figsize=(15,12))
plot_tree(decision_tree, max_depth=2, fontsize=14, feature_names=X.columns, 
          class_names={0:'dissatisfied', 1:'satisfied'}, filled=True);
plt.show()

#hyperparameter tuning 
tree_para = {'max_depth':[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,30,40,50],
             'min_samples_leaf': [2,3,4,5,6,7,8,9, 10, 15, 20, 50]}

scoring = {'accuracy', 'precision', 'recall', 'f1'}


tuned_decision_tree = DecisionTreeClassifier(random_state=0)

clf = GridSearchCV(tuned_decision_tree, 
                   tree_para, 
                   scoring = scoring, 
                   cv=5, 
                   refit="f1")

clf.fit(X_train, y_train)

# compute best combination of values
clf.best_estimator_
print("Best Avg. Validation Score: ", "%.4f" % clf.best_score_)

#determine best decision tree
results = pd.DataFrame(columns=[])

def make_results(model_name, model_object):
results = pd.DataFrame(columns=['Model', 'F1', 'Recall', 'Precision', 'Accuracy'])

def make_results(model_name, model_object):
    """
    Accepts as arguments a model name (your choice - string) and
    a fit GridSearchCV model object.

    Returns a pandas df with the F1, recall, precision, and accuracy scores
    for the model with the best mean F1 score across all validation folds.  
    """

    # Get all the results from the CV and put them in a df.
    cv_results = pd.DataFrame(model_object.cv_results_)

    # Isolate the row of the df with the max(mean f1 score).
    best_estimator_results = cv_results.iloc[cv_results['mean_test_f1'].idxmax(), :]

    # Extract accuracy, precision, recall, and f1 score from that row.
    f1 = best_estimator_results.mean_test_f1
    recall = best_estimator_results.mean_test_recall
    precision = best_estimator_results.mean_test_precision
    accuracy = best_estimator_results.mean_test_accuracy

    # Create a table of results.
    table = pd.DataFrame()
    table = table.append({'Model': model_name,
                          'F1': f1,
                          'Recall': recall,
                          'Precision': precision,
                          'Accuracy': accuracy},
                         ignore_index=True)

    return table

result_table = make_results("Tuned Decision Tree", clf)

result_table
